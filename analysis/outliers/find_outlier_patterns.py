#!/usr/bin/env python3
"""í° ì˜¤ì°¨ë¥¼ ë³´ì´ëŠ” íŒ¨í„´ ë¶„ì„"""
import torch
import json
from pathlib import Path
from collections import defaultdict
import sys
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from train_sliding import SlidingWindowDataset
from model import HyenaPositioning

def analyze_outliers(checkpoint_path: Path, data_dir: Path, threshold: float = 5.0):
    """threshold ì´ìƒì˜ ì˜¤ì°¨ë¥¼ ë³´ì´ëŠ” ìƒ˜í”Œ ë¶„ì„"""

    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    with (data_dir / "meta.json").open() as f:
        meta = json.load(f)

    # ëª¨ë¸ ë¡œë“œ
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    model = HyenaPositioning(
        input_dim=meta["n_features"],
        hidden_dim=384,
        depth=10
    ).to(device)

    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint["model_state"])
    model.eval()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_dataset = SlidingWindowDataset(data_dir / "test.jsonl")
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=64, shuffle=False
    )

    # Outlier ìˆ˜ì§‘
    outliers = []
    all_errors = []
    all_positions = []  # ëª¨ë“  ìƒ˜í”Œì˜ ì‹¤ì œ ìœ„ì¹˜

    with torch.no_grad():
        for batch_idx, (features, targets) in enumerate(test_loader):
            features = features.to(device)
            targets = targets.to(device)

            # edge_ids ìƒì„± (ëª¨ë‘ 0ìœ¼ë¡œ)
            edge_ids = torch.zeros(features.size(0), dtype=torch.long, device=device)

            outputs = model(features, edge_ids)  # (batch, seq_len, 2)
            preds = outputs[:, -1, :]  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ë§Œ ì‚¬ìš© (batch, 2)

            # ì—­ì •ê·œí™”
            COORD_CENTER = torch.tensor([-41.0, 0.0], device=device)
            COORD_SCALE = 50.0

            preds_real = preds * COORD_SCALE + COORD_CENTER
            targets_real = targets * COORD_SCALE + COORD_CENTER

            # ìœ í´ë¦¬ë“œ ê±°ë¦¬
            distances = torch.norm(preds_real - targets_real, dim=1)

            for i, dist in enumerate(distances):
                sample_idx = batch_idx * 64 + i
                error = dist.item()
                all_errors.append(error)

                # ëª¨ë“  ìƒ˜í”Œì˜ ìœ„ì¹˜ ì €ì¥
                all_positions.append({
                    "x": targets_real[i, 0].item(),
                    "y": targets_real[i, 1].item(),
                    "error": error
                })

                if error > threshold:
                    outliers.append({
                        "sample_idx": sample_idx,
                        "error": error,
                        "pred": preds_real[i].cpu().tolist(),
                        "target": targets_real[i].cpu().tolist(),
                        "pred_norm": preds[i].cpu().tolist(),
                        "target_norm": targets[i].cpu().tolist()
                    })

    # í†µê³„
    print("=" * 80)
    print("ğŸ” Outlier ë¶„ì„")
    print("=" * 80)
    print(f"ì´ ìƒ˜í”Œ: {len(all_errors)}")
    print(f"Outliers (>{threshold}m): {len(outliers)} ({len(outliers)/len(all_errors)*100:.1f}%)")
    print(f"ìµœëŒ€ ì˜¤ì°¨: {max(all_errors):.3f}m")
    print()

    # ìƒìœ„ 10ê°œ outlier
    outliers_sorted = sorted(outliers, key=lambda x: x["error"], reverse=True)
    print("ğŸ“Š ìƒìœ„ 10ê°œ Outlier:")
    print("-" * 80)
    for i, out in enumerate(outliers_sorted[:10], 1):
        print(f"{i}. Sample {out['sample_idx']}: Error={out['error']:.3f}m")
        print(f"   Target: ({out['target'][0]:.2f}, {out['target'][1]:.2f})")
        print(f"   Pred:   ({out['pred'][0]:.2f}, {out['pred'][1]:.2f})")
        print(f"   Norm Target: ({out['target_norm'][0]:.4f}, {out['target_norm'][1]:.4f})")
        print(f"   Norm Pred:   ({out['pred_norm'][0]:.4f}, {out['pred_norm'][1]:.4f})")
        print()

    # êµ¬ê°„ë³„ ì „ì²´ ë°ì´í„° ë¶„í¬
    print("ğŸ“Š êµ¬ê°„ë³„ ë°ì´í„° ë¶„í¬ vs Outlier ë¹„ìœ¨:")
    print("-" * 80)

    # X ì¢Œí‘œ êµ¬ê°„ë³„ í†µê³„
    x_bin_total = defaultdict(int)
    x_bin_outliers = defaultdict(int)

    for pos in all_positions:
        x = pos["x"]
        x_bin = int(x // 10) * 10
        x_bin_total[x_bin] += 1
        if pos["error"] > threshold:
            x_bin_outliers[x_bin] += 1

    print("X ì¢Œí‘œ ë¶„í¬ (10m ë‹¨ìœ„):")
    print(f"{'êµ¬ê°„':<20} {'ì „ì²´':<8} {'Outlier':<10} {'ë¹„ìœ¨':<10} {'ê·¸ë˜í”„'}")
    print("-" * 80)
    for x_bin in sorted(x_bin_total.keys()):
        total = x_bin_total[x_bin]
        outlier_count = x_bin_outliers[x_bin]
        ratio = (outlier_count / total * 100) if total > 0 else 0
        bar = "â–ˆ" * int(ratio // 2)
        print(f"  {x_bin:>4}m ~ {x_bin+10:>4}m: {total:>6}ê°œ  {outlier_count:>3}ê°œ  {ratio:>6.2f}%  {bar}")

    print()

    # Y ì¢Œí‘œ êµ¬ê°„ë³„ í†µê³„
    y_bin_total = defaultdict(int)
    y_bin_outliers = defaultdict(int)

    for pos in all_positions:
        y = pos["y"]
        y_bin = int(y // 5) * 5
        y_bin_total[y_bin] += 1
        if pos["error"] > threshold:
            y_bin_outliers[y_bin] += 1

    print("Y ì¢Œí‘œ ë¶„í¬ (5m ë‹¨ìœ„):")
    print(f"{'êµ¬ê°„':<20} {'ì „ì²´':<8} {'Outlier':<10} {'ë¹„ìœ¨':<10} {'ê·¸ë˜í”„'}")
    print("-" * 80)
    for y_bin in sorted(y_bin_total.keys()):
        total = y_bin_total[y_bin]
        outlier_count = y_bin_outliers[y_bin]
        ratio = (outlier_count / total * 100) if total > 0 else 0
        bar = "â–ˆ" * int(ratio // 2)
        print(f"  {y_bin:>4}m ~ {y_bin+5:>4}m: {total:>6}ê°œ  {outlier_count:>3}ê°œ  {ratio:>6.2f}%  {bar}")

    print("=" * 80)

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--checkpoint", default="models/hyena_mag4/checkpoints/best.pt")
    parser.add_argument("--data-dir", default="data/sliding_mag4")
    parser.add_argument("--threshold", type=float, default=5.0, help="Outlier ê¸°ì¤€ (ë¯¸í„°)")

    args = parser.parse_args()

    analyze_outliers(
        Path(args.checkpoint),
        Path(args.data_dir),
        args.threshold
    )
